import pandas as pd
import numpy as np
import re
from sklearn.impute import KNNImputer

print("üîç Mapeamento + KNN Imputer")
print("=" * 60)

# =============================
# PARTE 1: PROCESSAMENTO PRINCIPAL
# =============================

print("\nüìã ETAPA 1: CARREGAMENTO E PROCESSAMENTO DOS DADOS")
print("-" * 50)

# Carregamento de dados (o CSV j√° tem cabe√ßalho)
df = pd.read_csv('dataset.csv')

# Tratamento inicial de valores ausentes
print("üìã Tratando valores ausentes iniciais...")
# Substituir strings vazias por NaN para tratamento consistente
df = df.replace(r'^\s*$', pd.NA, regex=True)
print(f"Registros com campo genero vazio: {df['genero'].isna().sum()}")

print("Primeiras Linhas:")
print(df.head())

# =============================
# PROCESSO DE LIMPEZA
# =============================

print("\nValores ausentes por coluna:")
print(df.isnull().sum())

print("\nRegistros duplicados:", df.duplicated().sum())
df = df.drop_duplicates()
print("Shape ap√≥s remo√ß√£o de duplicados:", df.shape)

# Corrigir idade
df['idade'] = pd.to_numeric(df['idade'], errors='coerce')
df['idade'] = df['idade'].fillna(df['idade'].median())
df['idade'] = df['idade'].astype(int)

# Normalizar valores de 'vive_no_brasil' ANTES do label encoding
df['vive_no_brasil'] = df['vive_no_brasil'].astype(str).str.strip().str.lower()
df['vive_no_brasil'] = df['vive_no_brasil'].replace({
    'true': 'sim',
    'false': 'n√£o',
    'nan': 'MISSING',
    'missing': 'MISSING'
})

# Extrair sigla do estado
def extrair_sigla_estado(valor):
    if isinstance(valor, str):
        match = re.search(r'\((\w{2})\)', valor)
        if match:
            return match.group(1)
    return 'MISSING'

df['estado_moradia'] = df['estado_moradia'].apply(extrair_sigla_estado)

# Preencher valores ausentes
df = df.fillna('MISSING')

# =============================
# MAPEAMENTOS MANUAIS
# =============================

print("\nüìã APLICANDO MAPEAMENTOS MANUAIS...")

# Mapeamento manual para G√äNERO
mapa_genero = {
    'Masculino': 0,
    'Feminino': 1,
    'MISSING': -1
}
df['genero'] = df['genero'].fillna('MISSING').astype(str).replace('', 'MISSING')
df['genero'] = df['genero'].map(mapa_genero).fillna(-1).astype(int)
print(f"‚úÖ G√™nero mapeado: {mapa_genero}")

# Mapeamento manual para ETNIA
mapa_etnia = {
    'Branca': 0,
    'Parda': 1,
    'Preta': 2,
    'Amarela': 3,
    'Ind√≠gena': 4,
    'Prefiro n√£o informar': 5,
    'MISSING': -1
}
df['etnia'] = df['etnia'].fillna('MISSING').astype(str).replace('', 'MISSING')
df['etnia'] = df['etnia'].map(mapa_etnia).fillna(-1).astype(int)
print(f"‚úÖ Etnia mapeada: {mapa_etnia}")

# Mapeamento manual para PCD
mapa_pcd = {
    'N√£o': 0,
    'Sim': 1,
    'MISSING': -1
}
df['pcd'] = df['pcd'].fillna('MISSING').astype(str).replace('', 'MISSING')
df['pcd'] = df['pcd'].map(mapa_pcd).fillna(-1).astype(int)
print(f"‚úÖ PCD mapeado: {mapa_pcd}")

# Mapeamento manual para VIVE NO BRASIL (j√° normalizado anteriormente)
mapa_vive_brasil = {
    'sim': 1,
    'n√£o': 0,
    'MISSING': -1
}
df['vive_no_brasil'] = df['vive_no_brasil'].map(mapa_vive_brasil).fillna(-1).astype(int)
print(f"‚úÖ Vive no Brasil mapeado: {mapa_vive_brasil}")

# Mapeamento manual para CLOUD PREFERIDA
mapa_cloud = {
    'Amazon Web Services (AWS)': 0,
    'Google Cloud (GCP)': 1,
    'Azure (Microsoft)': 2,
    'N√£o sei opinar': 3,
    'N√£o utilizo': 4,
    'Oracle Cloud': 5,
    'IBM Cloud': 6,
    'Outra op√ß√£o': 7,
    'MISSING': -1
}
df['cloud_preferida'] = df['cloud_preferida'].fillna('MISSING').astype(str).replace('', 'MISSING')
df['cloud_preferida'] = df['cloud_preferida'].map(mapa_cloud).fillna(-1).astype(int)
print(f"‚úÖ Cloud preferida mapeada: {mapa_cloud}")

# Mapeamento manual para CARGO
mapa_cargo = {
    'Cientista de Dados/Data Scientist': 0,
    'Analista de Dados/Data Analyst': 1,
    'Engenheiro de Dados/Data Engineer': 2,
    'Desenvolvedor/ Engenheiro de Software/ Analista de Sistemas': 3,
    'Analista de BI/BI Analyst': 4,
    'DBA/Administrador de Banco de Dados': 5,
    'Professor': 6,
    'Analista de Neg√≥cios/Business Analyst': 7,
    'Analista de Suporte/Analista T√©cnico': 8,
    'Gerente/Coordenador de TI': 9,
    'Outra Op√ß√£o': 10,
    'MISSING': -1
}
df['cargo'] = df['cargo'].fillna('MISSING').astype(str).replace('', 'MISSING')
df['cargo'] = df['cargo'].map(mapa_cargo).fillna(-1).astype(int)
print(f"‚úÖ Cargo mapeado: {mapa_cargo}")

# Mapeamento manual para FORMA√á√ÉO
mapa_formacao = {
    'Computa√ß√£o / Engenharia de Software / Sistemas de Informa√ß√£o/ TI': 0,
    'Estat√≠stica/ Matem√°tica / Matem√°tica Computacional/ Ci√™ncias Atuariais': 1,
    'Outras Engenharias': 2,
    'Economia/ Administra√ß√£o / Contabilidade / Finan√ßas/ Neg√≥cios': 3,
    'Ci√™ncias Biol√≥gicas/ Farm√°cia/ Medicina/ √Årea da Sa√∫de': 4,
    'Ci√™ncias Sociais': 5,
    'Qu√≠mica / F√≠sica': 6,
    'Marketing / Publicidade / Comunica√ß√£o / Jornalismo': 7,
    'Outra op√ß√£o': 8,
    'MISSING': -1
}
df['formacao'] = df['formacao'].fillna('MISSING').astype(str).replace('', 'MISSING')
df['formacao'] = df['formacao'].map(mapa_formacao).fillna(-1).astype(int)
print(f"‚úÖ Forma√ß√£o mapeada: {mapa_formacao}")

# Obter valor codificado de 'sim' para 'vive_no_brasil'
sim_value = 1  # Definido manualmente no mapeamento acima

# Mapeamento de estados brasileiros (siglas)
mapa_estados = {
    'AC': 0, 'AL': 1, 'AP': 2, 'AM': 3, 'BA': 4, 'CE': 5, 'DF': 6, 'ES': 7, 'GO': 8,
    'MA': 9, 'MT': 10, 'MS': 11, 'MG': 12, 'PA': 13, 'PB': 14, 'PR': 15, 'PE': 16,
    'PI': 17, 'RJ': 18, 'RN': 19, 'RS': 20, 'RO': 21, 'RR': 22, 'SC': 23, 'SP': 24,
    'SE': 25, 'TO': 26, 'MISSING': -1
}

# Aplicar mapeamento condicional de estado_moradia
df['estado_moradia'] = df.apply(
    lambda row: mapa_estados.get(row['estado_moradia'], -1)
    if row['vive_no_brasil'] == sim_value else -1,
    axis=1
)

# Mapeamento do n√≠vel de ensino
mapa_nivel = {
    'fundamental': 0,
    'medio': 1,
    'tecnico': 2,
    'superior incompleto': 3,
    'superior completo': 4,
    'pos-gradua√ß√£o': 5,
    'p√≥s-gradua√ß√£o': 5,
    'mestrado': 6,
    'doutorado': 7,
    'MISSING': -1,
    'gradua√ß√£o/bacharelado': 4
}
df['nivel_ensino'] = df['nivel_ensino'].str.lower().map(mapa_nivel).fillna(-1).astype(int)

# Mapeamento do tempo de experi√™ncia
mapa_experiencia = {
    'menos de 1 ano': 0,
    '1 a 2 anos': 1,
    '1-2 anos': 1,
    'de 1 a 2 anos': 1,
    '2 a 3 anos': 2,
    '3 a 4 anos': 2,
    '3-5 anos': 2,
    '5-10 anos': 3,
    'mais de 10 anos': 4,
    'MISSING': -1
}
df['tempo_experiencia_dados'] = df['tempo_experiencia_dados'].str.lower().map(mapa_experiencia).fillna(-1).astype(int)

# Fun√ß√£o para extrair o banco/linguagem principal (primeiro da lista)
def extrair_principal(x):
    if isinstance(x, str) and x != 'MISSING' and x.strip() != '':
        items = [i.strip() for i in x.split(',')]
        return items[0] if items else 'MISSING'
    return 'MISSING'

# Processar bancos de dados - manter apenas o principal
df['bancos_de_dados'] = df['bancos_de_dados'].apply(extrair_principal)

# Mapeamento manual para BANCOS DE DADOS (principais)
mapa_bancos = {
    'PostgreSQL': 0,
    'MySQL': 1,
    'SQL SERVER': 2,
    'Oracle': 3,
    'Google BigQuery': 4,
    'Microsoft Access': 5,
    'SQLite': 6,
    'Amazon Athena': 7,
    'MongoDB': 8,
    'Hive': 9,
    'Amazon Redshift': 10,
    'Databricks': 11,
    'Snowflake': 12,
    'DB2': 13,
    'Cassandra': 14,
    'N√£o utilizo': 15,
    'MISSING': -1
}
df['bancos_de_dados'] = df['bancos_de_dados'].fillna('MISSING').astype(str).replace('', 'MISSING')
df['bancos_de_dados'] = df['bancos_de_dados'].map(mapa_bancos).fillna(-1).astype(int)
print(f"‚úÖ Bancos de dados mapeados: {mapa_bancos}")

# Processar linguagens preferidas - manter apenas a principal
df['linguagens_preferidas'] = df['linguagens_preferidas'].apply(extrair_principal)

# Mapeamento manual para LINGUAGENS PREFERIDAS (principais)
mapa_linguagens = {
    'Python': 0,
    'R': 1,
    'SQL': 2,
    'javascript': 3,
    'Java': 4,
    'C/C++/C#': 5,
    'Scala': 6,
    'Go': 7,
    'Julia': 8,
    'SAS': 9,
    'Excel': 10,
    'Dax': 11,
    'M': 12,
    'N√£o uso': 13,
    'N√£o utilizo': 14,
    'MISSING': -1
}
df['linguagens_preferidas'] = df['linguagens_preferidas'].fillna('MISSING').astype(str).replace('', 'MISSING')
df['linguagens_preferidas'] = df['linguagens_preferidas'].map(mapa_linguagens).fillna(-1).astype(int)
print(f"‚úÖ Linguagens preferidas mapeadas: {mapa_linguagens}")

# Resetar √≠ndice para evitar problemas com √≠ndices n√£o num√©ricos
df = df.reset_index(drop=True)

# Diagn√≥stico: verificar se restam colunas texto antes da convers√£o final
print("\nColunas do tipo 'object' antes da convers√£o para inteiro:")
print(df.dtypes[df.dtypes == 'object'])

# Preencher valores ausentes e converter colunas num√©ricas para int
df = df.fillna(-1)
colunas_numericas = df.select_dtypes(include=['float64', 'int64']).columns
df[colunas_numericas] = df[colunas_numericas].astype(int)

# removendo duplicatas
df = df.drop_duplicates()

# Salvar resultado (mantendo todas as 13 colunas)
print(f"\nüìà Total de colunas finais: {df.shape[1]} (objetivo: 13)")
print(f"Colunas: {list(df.columns)}")

# Verificar se todas as colunas s√£o num√©ricas
print(f"\n‚úÖ Verifica√ß√£o final:")
for col in df.columns:
    tipo = df[col].dtype
    min_val = df[col].min()
    max_val = df[col].max()
    print(f"{col}: {tipo} (min: {min_val}, max: {max_val})")

# Salvar dados processados
df.to_csv('dados_processados.csv', index=False)
print("‚úÖ Arquivo 'dados_processados.csv' salvo com sucesso.")

# =============================
# PARTE 2: KNN IMPUTER
# =============================

print("\nüìã ETAPA 2: AN√ÅLISE E IMPUTA√á√ÉO KNN")
print("-" * 50)

# An√°lise de valores ausentes (-1)
print("\nüìä An√°lise de Valores Ausentes (representados como -1):")
print("-" * 50)

# No processamento acima, valores ausentes s√£o codificados como -1
missing_count = (df == -1).sum()
missing_percent = (missing_count / len(df) * 100).round(2)

missing_summary = pd.DataFrame({
    'Coluna': missing_count.index,
    'Valores_Ausentes': missing_count.values,
    'Percentual': missing_percent.values
})

print(missing_summary)

# Identificar colunas com valores ausentes
colunas_com_missing = missing_count[missing_count > 0].index.tolist()
print(f"\nColunas com valores ausentes: {colunas_com_missing}")
print(f"Total de valores ausentes: {missing_count.sum()}")

if missing_count.sum() == 0:
    print("üéâ N√£o h√° valores ausentes para imputar!")
    print("‚úÖ Processo finalizado - dados j√° est√£o completos!")
else:
    # Mapeamentos reversos (para interpreta√ß√£o)
    mapeamentos_reversos = {
        'genero': {0: 'Masculino', 1: 'Feminino', -1: 'MISSING'},
        'etnia': {0: 'Branca', 1: 'Parda', 2: 'Preta', 3: 'Amarela', 4: 'Ind√≠gena', 5: 'Prefiro n√£o informar', -1: 'MISSING'},
        'pcd': {0: 'N√£o', 1: 'Sim', -1: 'MISSING'},
        'vive_no_brasil': {0: 'N√£o', 1: 'Sim', -1: 'MISSING'},
        'formacao': {0: 'Computa√ß√£o/TI', 1: 'Estat√≠stica/Matem√°tica', 2: 'Outras Engenharias',
                    3: 'Economia/Administra√ß√£o', 4: 'Ci√™ncias Biol√≥gicas', 5: 'Ci√™ncias Sociais',
                    6: 'Qu√≠mica/F√≠sica', 7: 'Marketing/Comunica√ß√£o', 8: 'Outra op√ß√£o', -1: 'MISSING'},
        'cargo': {0: 'Cientista de Dados', 1: 'Analista de Dados', 2: 'Engenheiro de Dados',
                 3: 'Desenvolvedor/Engenheiro Software', 4: 'Analista de BI', 5: 'DBA',
                 6: 'Professor', 7: 'Analista de Neg√≥cios', 8: 'Analista de Suporte',
                 9: 'Gerente/Coordenador TI', 10: 'Outra Op√ß√£o', -1: 'MISSING'}
    }

    # Prepara√ß√£o para KNN Imputer
    def preparar_dados_knn(df, colunas_imputar):
        """
        Prepara dados para KNN, convertendo -1 para NaN
        """
        df_knn = df.copy()

        # Converter -1 para NaN apenas nas colunas que ser√£o imputadas
        for col in colunas_imputar:
            df_knn.loc[df_knn[col] == -1, col] = np.nan

        print(f"üìã Prepara√ß√£o para KNN:")
        print(f"Colunas para imputa√ß√£o: {colunas_imputar}")
        print(f"Valores NaN ap√≥s convers√£o:")
        for col in colunas_imputar:
            nan_count = df_knn[col].isna().sum()
            print(f"  {col}: {nan_count} valores NaN")

        return df_knn

    # Preparar dados apenas para colunas com missing
    df_knn = preparar_dados_knn(df, colunas_com_missing)

    # Aplica√ß√£o do KNN Imputer
    def aplicar_knn_inteligente(df, colunas_imputar, k_neighbors=5):
        """
        Aplica KNN Imputer de forma inteligente
        """
        print(f"\nüîÑ Aplicando KNN Imputer (k={k_neighbors})")
        print("-" * 40)

        # Criar c√≥pia dos dados
        df_imputed = df.copy()

        # Configurar KNN Imputer
        imputer = KNNImputer(
            n_neighbors=k_neighbors,
            weights='distance',  # Vizinhos mais pr√≥ximos t√™m maior peso
            metric='nan_euclidean'  # M√©trica que lida bem com NaN
        )

        # Aplicar imputa√ß√£o apenas nas colunas necess√°rias
        if colunas_imputar:
            print("Aplicando imputa√ß√£o...")

            # Imputar valores
            dados_imputados = imputer.fit_transform(df[colunas_imputar])

            # Arredondar valores para inteiros (j√° que s√£o categ√≥ricas ordinais)
            dados_imputados = np.round(dados_imputados).astype(int)

            # Atualizar dataframe
            for i, col in enumerate(colunas_imputar):
                df_imputed[col] = dados_imputados[:, i]

            print("‚úÖ Imputa√ß√£o conclu√≠da!")

            # Verificar se ainda h√° valores ausentes
            missing_after = (df_imputed == -1).sum().sum()
            nan_after = df_imputed.isna().sum().sum()
            print(f"Valores -1 restantes: {missing_after}")
            print(f"Valores NaN restantes: {nan_after}")

        return df_imputed, imputer

    # Testar diferentes valores de k
    resultados_k = {}
    k_values = [3, 5, 7, 10]

    print("\nüéØ Testando Diferentes Valores de K:")
    print("=" * 40)

    for k in k_values:
        print(f"\n--- Testando k={k} ---")
        df_result, imputer = aplicar_knn_inteligente(df_knn, colunas_com_missing, k)
        resultados_k[k] = df_result

        # Estat√≠sticas resumidas
        for col in colunas_com_missing:
            original_missing = (df[col] == -1).sum()
            valores_imputados = df_result[col][df[col] == -1]

            if len(valores_imputados) > 0:
                print(f"  {col}: {original_missing} valores imputados")
                print(f"    Distribui√ß√£o: {valores_imputados.value_counts().to_dict()}")

    # Valida√ß√£o da qualidade
    def validar_qualidade_imputacao(df_original, df_imputado, coluna):
        """
        Valida a qualidade da imputa√ß√£o comparando distribui√ß√µes
        """
        if coluna not in df_original.columns or coluna not in df_imputado.columns:
            return

        print(f"\nüìä Valida√ß√£o para {coluna}:")
        print("-" * 30)

        # Valores originais (n√£o missing)
        valores_originais = df_original[df_original[coluna] != -1][coluna]

        # Valores imputados
        mask_era_missing = df_original[coluna] == -1
        valores_imputados = df_imputado[mask_era_missing][coluna]

        if len(valores_imputados) > 0:
            print(f"Distribui√ß√£o original:")
            dist_orig = valores_originais.value_counts().sort_index()
            for val, count in dist_orig.items():
                nome_val = mapeamentos_reversos.get(coluna, {}).get(val, val)
                pct = (count / len(valores_originais) * 100)
                print(f"  {nome_val}: {count} ({pct:.1f}%)")

            print(f"\nDistribui√ß√£o imputada:")
            dist_imp = valores_imputados.value_counts().sort_index()
            for val, count in dist_imp.items():
                nome_val = mapeamentos_reversos.get(coluna, {}).get(val, val)
                pct = (count / len(valores_imputados) * 100)
                print(f"  {nome_val}: {count} ({pct:.1f}%)")

    # Validar qualidade para k=5 (valor m√©dio)
    if 5 in resultados_k:
        print("\nüîç VALIDA√á√ÉO DE QUALIDADE (k=5):")
        print("=" * 50)

        for col in colunas_com_missing[:3]:  # Primeiras 3 colunas para n√£o ser muito longo
            validar_qualidade_imputacao(df, resultados_k[5], col)

    # Salvar resultados
    melhor_k = 5
    df_final = resultados_k[melhor_k]

    print(f"\nüíæ Salvando Resultado Final (k={melhor_k}):")
    print("-" * 40)

    # Verifica√ß√£o final
    print(f"Shape final: {df_final.shape}")
    print(f"Valores -1 restantes: {(df_final == -1).sum().sum()}")
    print(f"Valores NaN restantes: {df_final.isna().sum().sum()}")

    # Salvar dataset com valores imputados
    df_final.to_csv('dados_knn_imputed.csv', index=False)
    print("‚úÖ Dataset salvo como 'dados_knn_imputed.csv'")

    # Relat√≥rio final
    print("\nüìã RELAT√ìRIO FINAL - KNN IMPUTATION")
    print("=" * 60)
    print(f"Dataset original: {df.shape}")
    print(f"Valores ausentes originais: {(df == -1).sum().sum()}")
    print(f"Colunas com missing: {len(colunas_com_missing)}")
    print(f"M√©todo: KNN Imputer (k={melhor_k})")
    print(f"Dataset final: {df_final.shape}")
    print(f"Valores ausentes finais: {(df_final == -1).sum().sum()}")

    if (df == -1).sum().sum() > 0:
        taxa_sucesso = 100 - ((df_final == -1).sum().sum() / (df == -1).sum().sum() * 100)
        print(f"Taxa de sucesso: {taxa_sucesso:.1f}%")


print("\n‚úÖ Pipeline Unificado Conclu√≠do com Sucesso!")